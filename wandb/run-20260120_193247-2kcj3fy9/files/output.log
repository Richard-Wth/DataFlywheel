wandb: Detected [openai] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
                                               
{'loss': 0.6335, 'grad_norm': 5.117620765640358, 'learning_rate': 0.0, 'epoch': 0.03}
{'loss': 0.6315, 'grad_norm': 5.25245700199529, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.06}
{'loss': 0.6518, 'grad_norm': 4.526586632029961, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.09}
{'loss': 0.5693, 'grad_norm': 4.311405270273974, 'learning_rate': 3e-06, 'epoch': 0.12}
{'loss': 0.5786, 'grad_norm': 4.278174557836256, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.16}
{'loss': 0.6057, 'grad_norm': 2.799783864605283, 'learning_rate': 5e-06, 'epoch': 0.19}
{'loss': 0.5695, 'grad_norm': 2.5255434151986176, 'learning_rate': 6e-06, 'epoch': 0.22}
{'loss': 0.5609, 'grad_norm': 2.813503684840806, 'learning_rate': 7e-06, 'epoch': 0.25}
{'loss': 0.5267, 'grad_norm': 2.4378327066242456, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.28}
{'loss': 0.5457, 'grad_norm': 2.3568996198733188, 'learning_rate': 9e-06, 'epoch': 0.31}
{'loss': 0.5713, 'grad_norm': 2.1184360720598305, 'learning_rate': 1e-05, 'epoch': 0.34}
{'loss': 0.5088, 'grad_norm': 1.8553539339305258, 'learning_rate': 9.996664241851197e-06, 'epoch': 0.38}
{'loss': 0.544, 'grad_norm': 1.631038252819196, 'learning_rate': 9.986661418317759e-06, 'epoch': 0.41}
{'loss': 0.5012, 'grad_norm': 1.6658898125293602, 'learning_rate': 9.970004876199731e-06, 'epoch': 0.44}
{'loss': 0.5596, 'grad_norm': 1.6445746566852781, 'learning_rate': 9.946716840375552e-06, 'epoch': 0.47}
{'loss': 0.5166, 'grad_norm': 1.3306111108578595, 'learning_rate': 9.91682838414733e-06, 'epoch': 0.5}
{'loss': 0.5218, 'grad_norm': 1.2417804615875938, 'learning_rate': 9.880379387779637e-06, 'epoch': 0.53}
{'loss': 0.5018, 'grad_norm': 1.1985414384216762, 'learning_rate': 9.837418485287126e-06, 'epoch': 0.56}
{'loss': 0.5595, 'grad_norm': 1.1496217705035412, 'learning_rate': 9.78800299954203e-06, 'epoch': 0.59}
{'loss': 0.522, 'grad_norm': 1.1978991270645687, 'learning_rate': 9.732198865788047e-06, 'epoch': 0.62}
{'loss': 0.5151, 'grad_norm': 1.114076934955414, 'learning_rate': 9.670080543662742e-06, 'epoch': 0.66}
{'loss': 0.5082, 'grad_norm': 0.9877661227006942, 'learning_rate': 9.601730917845798e-06, 'epoch': 0.69}
{'loss': 0.5083, 'grad_norm': 0.9708257501420918, 'learning_rate': 9.527241187465735e-06, 'epoch': 0.72}
{'loss': 0.5267, 'grad_norm': 1.0051628755733781, 'learning_rate': 9.446710744412595e-06, 'epoch': 0.75}
{'loss': 0.4976, 'grad_norm': 0.9684856527993342, 'learning_rate': 9.36024704071904e-06, 'epoch': 0.78}
{'loss': 0.5257, 'grad_norm': 0.9600342868653964, 'learning_rate': 9.267965445186733e-06, 'epoch': 0.81}
{'loss': 0.5335, 'grad_norm': 0.8990796819467186, 'learning_rate': 9.16998908944939e-06, 'epoch': 0.84}
{'loss': 0.5391, 'grad_norm': 0.9043923400481676, 'learning_rate': 9.066448703677828e-06, 'epoch': 0.88}
{'loss': 0.4985, 'grad_norm': 0.873576465794327, 'learning_rate': 8.957482442146271e-06, 'epoch': 0.91}
{'loss': 0.4862, 'grad_norm': 0.8592310875796021, 'learning_rate': 8.843235698892661e-06, 'epoch': 0.94}
{'loss': 0.5262, 'grad_norm': 0.7948539531743694, 'learning_rate': 8.72386091371891e-06, 'epoch': 0.97}
{'loss': 0.5066, 'grad_norm': 0.8396859178134495, 'learning_rate': 8.599517368789981e-06, 'epoch': 1.0}
{'loss': 0.5163, 'grad_norm': 0.8957146605590475, 'learning_rate': 8.470370976103171e-06, 'epoch': 1.03}
{'loss': 0.5083, 'grad_norm': 0.8729705619826201, 'learning_rate': 8.336594056111197e-06, 'epoch': 1.06}
{'loss': 0.5203, 'grad_norm': 0.8789811175842445, 'learning_rate': 8.198365107794457e-06, 'epoch': 1.09}
{'loss': 0.4846, 'grad_norm': 0.8191708362307364, 'learning_rate': 8.055868570489247e-06, 'epoch': 1.12}
{'loss': 0.4605, 'grad_norm': 0.8231985660678518, 'learning_rate': 7.909294577789765e-06, 'epoch': 1.16}
{'loss': 0.4786, 'grad_norm': 0.8169460696274476, 'learning_rate': 7.75883870385223e-06, 'epoch': 1.19}
{'loss': 0.5365, 'grad_norm': 0.9229356190009173, 'learning_rate': 7.604701702439652e-06, 'epoch': 1.22}
{'loss': 0.4613, 'grad_norm': 0.863920575159022, 'learning_rate': 7.447089239055428e-06, 'epoch': 1.25}
{'loss': 0.5346, 'grad_norm': 0.941869857650112, 'learning_rate': 7.286211616523193e-06, 'epoch': 1.28}
{'loss': 0.515, 'grad_norm': 0.8807121514331442, 'learning_rate': 7.122283494379076e-06, 'epoch': 1.31}
{'loss': 0.5031, 'grad_norm': 0.8056543629243565, 'learning_rate': 6.95552360245078e-06, 'epoch': 1.34}
{'loss': 0.5651, 'grad_norm': 0.804109500198339, 'learning_rate': 6.786154449005664e-06, 'epoch': 1.38}
{'loss': 0.485, 'grad_norm': 0.8088037807425524, 'learning_rate': 6.614402023857231e-06, 'epoch': 1.41}
